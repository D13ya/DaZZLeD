{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4c8053",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repo (only needed in Colab)\n",
    "import os\n",
    "if not os.path.exists('DaZZLeD'):\n",
    "    !git clone https://github.com/D13ya/DaZZLeD.git\n",
    "    %cd DaZZLeD/ml-core\n",
    "else:\n",
    "    %cd DaZZLeD/ml-core\n",
    "\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f363c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from models.recursive_student import RecursiveHasher\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbba1d4",
   "metadata": {},
   "source": [
    "## 2. Model Architecture Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with default params\n",
    "STATE_DIM = 128\n",
    "HASH_DIM = 96\n",
    "RECURSION_STEPS = 16\n",
    "\n",
    "model = RecursiveHasher(state_dim=STATE_DIM, hash_dim=HASH_DIM)\n",
    "model.eval()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: ~{total_params * 4 / 1024 / 1024:.2f} MB (float32)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f6d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass with dummy input\n",
    "batch_size = 4\n",
    "image_size = 224\n",
    "\n",
    "dummy_img = torch.randn(batch_size, 3, image_size, image_size)\n",
    "dummy_state = torch.zeros(batch_size, STATE_DIM)\n",
    "\n",
    "with torch.no_grad():\n",
    "    next_state, hash_out = model(dummy_img, dummy_state)\n",
    "\n",
    "print(f\"Input image shape: {dummy_img.shape}\")\n",
    "print(f\"Input state shape: {dummy_state.shape}\")\n",
    "print(f\"Output state shape: {next_state.shape}\")\n",
    "print(f\"Output hash shape: {hash_out.shape}\")\n",
    "print(f\"Hash L2 norm (should be ~1.0): {torch.norm(hash_out, dim=1).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b0ff3",
   "metadata": {},
   "source": [
    "## 3. Recursive Inference Test\n",
    "\n",
    "The key innovation is running the model recursively 16 times, refining the hash at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc68871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_inference(model, image, steps=16):\n",
    "    \"\"\"Run recursive inference for the specified number of steps.\"\"\"\n",
    "    batch_size = image.size(0)\n",
    "    state = torch.zeros(batch_size, STATE_DIM, device=image.device)\n",
    "    \n",
    "    hashes = []\n",
    "    with torch.no_grad():\n",
    "        for step in range(steps):\n",
    "            state, hash_out = model(image, state)\n",
    "            hashes.append(hash_out.clone())\n",
    "    \n",
    "    return hashes\n",
    "\n",
    "# Run recursive inference\n",
    "hashes = recursive_inference(model, dummy_img, steps=RECURSION_STEPS)\n",
    "\n",
    "print(f\"Generated {len(hashes)} hash vectors\")\n",
    "print(f\"Final hash shape: {hashes[-1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7063c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze hash stability across recursive steps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute cosine similarity between consecutive steps\n",
    "similarities = []\n",
    "for i in range(1, len(hashes)):\n",
    "    sim = F.cosine_similarity(hashes[i], hashes[i-1], dim=1).mean().item()\n",
    "    similarities.append(sim)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(hashes)), similarities, 'b-o')\n",
    "plt.xlabel('Recursion Step')\n",
    "plt.ylabel('Cosine Similarity with Previous')\n",
    "plt.title('Hash Convergence Over Recursion')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(True)\n",
    "\n",
    "# Compute similarity to final hash\n",
    "final_hash = hashes[-1]\n",
    "similarities_to_final = []\n",
    "for h in hashes:\n",
    "    sim = F.cosine_similarity(h, final_hash, dim=1).mean().item()\n",
    "    similarities_to_final.append(sim)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(hashes)), similarities_to_final, 'r-o')\n",
    "plt.xlabel('Recursion Step')\n",
    "plt.ylabel('Cosine Similarity to Final Hash')\n",
    "plt.title('Convergence to Final Hash')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87e5f8",
   "metadata": {},
   "source": [
    "## 4. Adversarial Robustness Test\n",
    "\n",
    "Test if small perturbations to input cause large changes in hash (they shouldn't after recursive refinement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa469be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_perturbation_robustness(model, image, epsilon_range, steps=16):\n",
    "    \"\"\"Test hash stability under input perturbations.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get baseline hash\n",
    "    baseline_hashes = recursive_inference(model, image, steps)\n",
    "    baseline_final = baseline_hashes[-1]\n",
    "    \n",
    "    for epsilon in epsilon_range:\n",
    "        # Add random noise\n",
    "        noise = torch.randn_like(image) * epsilon\n",
    "        perturbed = image + noise\n",
    "        \n",
    "        # Get perturbed hash\n",
    "        perturbed_hashes = recursive_inference(model, perturbed, steps)\n",
    "        perturbed_final = perturbed_hashes[-1]\n",
    "        \n",
    "        # Compute similarity\n",
    "        sim = F.cosine_similarity(baseline_final, perturbed_final, dim=1).mean().item()\n",
    "        results.append((epsilon, sim))\n",
    "        print(f\"Epsilon={epsilon:.4f}: Cosine Similarity={sim:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test with various noise levels\n",
    "epsilons = [0.001, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "test_img = torch.randn(1, 3, 224, 224)\n",
    "results = test_perturbation_robustness(model, test_img, epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot robustness results\n",
    "epsilons, sims = zip(*results)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epsilons, sims, 'g-o', linewidth=2, markersize=8)\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='0.9 threshold')\n",
    "plt.xlabel('Noise Level (epsilon)', fontsize=12)\n",
    "plt.ylabel('Cosine Similarity to Original', fontsize=12)\n",
    "plt.title('Hash Robustness to Input Perturbations', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e33729",
   "metadata": {},
   "source": [
    "## 5. ONNX Export Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe78324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Export to ONNX\n",
    "onnx_path = \"test_model.onnx\"\n",
    "\n",
    "model.eval()\n",
    "dummy_img = torch.randn(1, 3, 224, 224)\n",
    "dummy_state = torch.zeros(1, STATE_DIM)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (dummy_img, dummy_state),\n",
    "    onnx_path,\n",
    "    input_names=[\"image\", \"prev_state\"],\n",
    "    output_names=[\"next_state\", \"hash\"],\n",
    "    opset_version=14,\n",
    "    dynamic_axes={\n",
    "        \"image\": {0: \"batch\"},\n",
    "        \"prev_state\": {0: \"batch\"},\n",
    "        \"next_state\": {0: \"batch\"},\n",
    "        \"hash\": {0: \"batch\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Exported ONNX model to {onnx_path}\")\n",
    "print(f\"File size: {os.path.getsize(onnx_path) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe910628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate ONNX model\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model validation passed!\")\n",
    "\n",
    "# Test ONNX runtime inference\n",
    "session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "# Run inference\n",
    "test_img = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "test_state = np.zeros((1, STATE_DIM), dtype=np.float32)\n",
    "\n",
    "outputs = session.run(None, {\"image\": test_img, \"prev_state\": test_state})\n",
    "next_state_onnx, hash_onnx = outputs\n",
    "\n",
    "print(f\"ONNX output state shape: {next_state_onnx.shape}\")\n",
    "print(f\"ONNX output hash shape: {hash_onnx.shape}\")\n",
    "print(f\"ONNX hash L2 norm: {np.linalg.norm(hash_onnx, axis=1).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ac143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PyTorch vs ONNX outputs\n",
    "with torch.no_grad():\n",
    "    pt_state, pt_hash = model(torch.from_numpy(test_img), torch.from_numpy(test_state))\n",
    "\n",
    "pt_hash_np = pt_hash.numpy()\n",
    "pt_state_np = pt_state.numpy()\n",
    "\n",
    "hash_diff = np.abs(pt_hash_np - hash_onnx).max()\n",
    "state_diff = np.abs(pt_state_np - next_state_onnx).max()\n",
    "\n",
    "print(f\"Max hash difference (PyTorch vs ONNX): {hash_diff:.8f}\")\n",
    "print(f\"Max state difference (PyTorch vs ONNX): {state_diff:.8f}\")\n",
    "\n",
    "if hash_diff < 1e-5 and state_diff < 1e-5:\n",
    "    print(\"✅ ONNX export matches PyTorch output!\")\n",
    "else:\n",
    "    print(\"⚠️ Warning: Numerical differences detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934775c",
   "metadata": {},
   "source": [
    "## 6. Latency Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f27eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_inference(model, device, num_runs=100, warmup=10):\n",
    "    \"\"\"Benchmark recursive inference latency.\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    test_img = torch.randn(1, 3, 224, 224).to(device)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = recursive_inference(model, test_img, steps=16)\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    for _ in range(num_runs):\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        _ = recursive_inference(model, test_img, steps=16)\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        times.append(time.perf_counter() - start)\n",
    "    \n",
    "    return times\n",
    "\n",
    "# Benchmark on CPU\n",
    "cpu_times = benchmark_inference(model, torch.device('cpu'), num_runs=50)\n",
    "print(f\"CPU Latency: {np.mean(cpu_times)*1000:.2f} ± {np.std(cpu_times)*1000:.2f} ms\")\n",
    "\n",
    "# Benchmark on GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    gpu_times = benchmark_inference(model, torch.device('cuda'), num_runs=100)\n",
    "    print(f\"GPU Latency: {np.mean(gpu_times)*1000:.2f} ± {np.std(gpu_times)*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5027b0",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "This notebook validates:\n",
    "1. ✅ Model architecture and parameter count\n",
    "2. ✅ Forward pass correctness\n",
    "3. ✅ Recursive inference convergence\n",
    "4. ✅ Perturbation robustness\n",
    "5. ✅ ONNX export and validation\n",
    "6. ✅ Inference latency\n",
    "\n",
    "**Next steps:**\n",
    "- Train the model using `training/train.py` (see COLAB.md)\n",
    "- Export trained model to ONNX\n",
    "- Integrate ONNX model into Go runtime"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
