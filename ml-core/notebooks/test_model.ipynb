{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DaZZLeD Hash Center Training Notebook (ResNet + Counterfactual VAE)\n",
        "\n",
        "**Goal:** Train the ResNet Hash Center model from `resnet.tex` with counterfactual VAE, CF\u2011SimCLR, DHD, PGD, and TTC checks.\n",
        "\n",
        "**Runtime:** Set Colab to GPU before running training cells.\n",
        "\n",
        "**Note:** If you do not have VAE weights yet, you must train them first (Step 3). If you want a quick run without VAE, set `--counterfactual-mode aug` in Step 4.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "DATA_ROOT = DRIVE_ROOT / \"data\"\n",
        "OUTPUT_ROOT = DRIVE_ROOT / \"outputs\"\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists('DaZZLeD'):\n",
        "    !git clone https://github.com/D13ya/DaZZLeD.git\n",
        "    %cd DaZZLeD/ml-core\n",
        "else:\n",
        "    %cd DaZZLeD/ml-core\n",
        "\n",
        "!pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Restore Dataset (Drive Zip)\n",
        "\n",
        "If you keep a dataset zip on Drive, extract it once to local disk (`/content/data`) for faster I/O.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "LOCAL_DATA = Path(\"/content/data\")\n",
        "LOCAL_DATA.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "zip_candidates = [\n",
        "    DRIVE_ROOT / \"data-cache/training-images.zip\",\n",
        "    DRIVE_ROOT / \"dazzled_dataset_v4.zip\",\n",
        "]\n",
        "\n",
        "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "\n",
        "def count_images(root: Path) -> int:\n",
        "    return sum(\n",
        "        1 for p in root.rglob(\"*\")\n",
        "        if p.is_file() and p.suffix.lower() in exts\n",
        "    )\n",
        "\n",
        "existing = count_images(LOCAL_DATA)\n",
        "if existing > 0:\n",
        "    print(f\"Local data already present under {LOCAL_DATA} ({existing} images); skipping extract.\")\n",
        "else:\n",
        "    extracted = 0\n",
        "    for zip_path in zip_candidates:\n",
        "        if not zip_path.exists():\n",
        "            continue\n",
        "        print(f\"Extracting {zip_path} -> {LOCAL_DATA}\")\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "            zf.extractall(LOCAL_DATA)\n",
        "        extracted = count_images(LOCAL_DATA)\n",
        "        print(f\"Extracted {extracted} images to {LOCAL_DATA}\")\n",
        "        if extracted > 0:\n",
        "            break\n",
        "    if extracted == 0:\n",
        "        print(\"No images found after extraction. Check the zip contents or path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Build Manifest (Optional)\n\nIf you already have a manifest at `/content/drive/MyDrive/dazzled/manifests/train.txt`, you can skip this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "LOCAL_DATA = Path(\"/content/data\")\n",
        "DRIVE_DATA = DRIVE_ROOT / \"data\"\n",
        "MANIFEST = DRIVE_ROOT / \"manifests/train.txt\"\n",
        "MANIFEST.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "\n",
        "def has_images(root: Path) -> bool:\n",
        "    if not root.exists():\n",
        "        return False\n",
        "    return any(p.is_file() and p.suffix.lower() in exts for p in root.rglob(\"*\"))\n",
        "\n",
        "DATA_ROOT = LOCAL_DATA if has_images(LOCAL_DATA) else DRIVE_DATA\n",
        "print(f\"Using DATA_ROOT: {DATA_ROOT}\")\n",
        "\n",
        "paths = [str(p) for p in DATA_ROOT.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts]\n",
        "MANIFEST.write_text(\"\\n\".join(paths))\n",
        "print(f\"Wrote {len(paths)} lines to {MANIFEST}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.5. Sanity Checks (Labels + Domains)\n",
        "\n",
        "Run this once after the manifest is created to verify labels/domains before any training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "MANIFEST = Path(\"/content/drive/MyDrive/dazzled/manifests/train.txt\")\n",
        "LABEL_REGEX = re.compile(r\"^((?:ffhq|openimages|openimg|mobileview)_\\d+|\\d+)\")\n",
        "DOMAIN_REGEX = re.compile(r\"/(ffhq|openimages|openimg|mobileview)/\")\n",
        "\n",
        "if not MANIFEST.exists():\n",
        "    raise FileNotFoundError(f\"Manifest not found: {MANIFEST}\")\n",
        "\n",
        "base = MANIFEST.resolve().parent\n",
        "lines = [line.strip() for line in MANIFEST.read_text().splitlines() if line.strip() and not line.strip().startswith('#')]\n",
        "total = len(lines)\n",
        "\n",
        "labels = []\n",
        "domains = []\n",
        "missing = []\n",
        "\n",
        "for line in lines:\n",
        "    parts = line.split()\n",
        "    path = Path(parts[0])\n",
        "    if not path.is_absolute():\n",
        "        path = (base / path).resolve()\n",
        "\n",
        "    label = parts[1] if len(parts) > 1 else None\n",
        "    if label is None:\n",
        "        match = LABEL_REGEX.search(path.name)\n",
        "        if match:\n",
        "            label = match.group(1)\n",
        "\n",
        "    domain = None\n",
        "    match = DOMAIN_REGEX.search(str(path))\n",
        "    if match:\n",
        "        domain = match.group(1)\n",
        "\n",
        "    labels.append(label)\n",
        "    domains.append(domain)\n",
        "    if not path.exists():\n",
        "        missing.append(str(path))\n",
        "\n",
        "label_known = [str(l) for l in labels if l is not None]\n",
        "domain_known = [str(d) for d in domains if d is not None]\n",
        "\n",
        "label_unique = len(set(label_known))\n",
        "label_unlabeled = total - len(label_known)\n",
        "label_pct = (label_unlabeled / total * 100.0) if total else 0.0\n",
        "\n",
        "domain_unique = len(set(domain_known))\n",
        "domain_unlabeled = total - len(domain_known)\n",
        "domain_pct = (domain_unlabeled / total * 100.0) if total else 0.0\n",
        "\n",
        "print(f\"Label stats: {label_unique} unique, {label_unlabeled}/{total} unlabeled ({label_pct:.1f}%).\")\n",
        "if label_known:\n",
        "    top = Counter(label_known).most_common(5)\n",
        "    top_str = \", \".join(f\"{k}:{v}\" for k, v in top)\n",
        "    print(f\"Top labels: {top_str}\")\n",
        "\n",
        "print(f\"Domain stats: {domain_unique} unique, {domain_unlabeled}/{total} unlabeled ({domain_pct:.1f}%).\")\n",
        "if domain_known:\n",
        "    top = Counter(domain_known).most_common(5)\n",
        "    top_str = \", \".join(f\"{k}:{v}\" for k, v in top)\n",
        "    print(f\"Top domains: {top_str}\")\n",
        "\n",
        "if missing:\n",
        "    print(f\"Missing files: {len(missing)} (showing up to 5)\")\n",
        "    for p in missing[:5]:\n",
        "        print(f\"  - {p}\")\n",
        "\n",
        "if label_unique < 2:\n",
        "    raise ValueError(\"CRITICAL: fewer than 2 unique labels found. Check regex/manifest.\")\n",
        "if domain_unique < 2:\n",
        "    print(\"WARNING: fewer than 2 unique domains found; VAE training will fail.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Counterfactual VAE (Save Weights)\n",
        "\n",
        "This produces the `--counterfactual-weights` file used by HashNet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DaZZLeD/ml-core\")\n",
        "\n",
        "!PYTHONPATH=/content/DaZZLeD/ml-core python training/train_counterfactual_vae.py   --data-list /content/drive/MyDrive/dazzled/manifests/train.txt   --epochs 10   --batch-size 128   --checkpoint-dir /content/drive/MyDrive/dazzled/outputs/cf_vae   --domain-mode regex   --domain-regex \"/(ffhq|openimages|openimg|mobileview)/\"   --cache-ram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train HashNet (ResNet + Hash Centers + CF/DHD/PGD)\n",
        "\n",
        "This uses the VAE weights from Step 3 and writes checkpoints to Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DaZZLeD/ml-core\")\n",
        "\n",
        "!PYTHONPATH=/content/DaZZLeD/ml-core python training/train_hashnet.py   --data-list /content/drive/MyDrive/dazzled/manifests/train.txt   --epochs 10   --batch-size 256   --center-mode hadamard   --center-neg-k 0   --counterfactual-mode vae   --counterfactual-weights /content/drive/MyDrive/dazzled/outputs/cf_vae/cf_vae_final.safetensors   --checkpoint-dir /content/drive/MyDrive/dazzled/outputs/hashnet   --domain-mode regex   --domain-regex \"/(ffhq|openimages|openimg|mobileview)/\"   --ttc-check   --cache-ram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. List Checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "CKPT_DIR = Path(\"/content/drive/MyDrive/dazzled/outputs/hashnet\")\n",
        "ckpts = sorted(CKPT_DIR.glob(\"*.safetensors\"))\n",
        "print(f\"Found {len(ckpts)} checkpoints\")\n",
        "for ckpt in ckpts:\n",
        "    print(ckpt.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. TTC Inference (Production-Style)\n",
        "\n",
        "Run the standalone TTC inference script on a sample image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DaZZLeD/ml-core\")\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "CKPT_DIR = Path(\"/content/drive/MyDrive/dazzled/outputs/hashnet\")\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/dazzled/data/ffhq/224/00000.jpg\"  # TODO: set a real path\n",
        "\n",
        "ckpts = sorted(CKPT_DIR.glob(\"*.safetensors\"))\n",
        "if not ckpts:\n",
        "    raise FileNotFoundError(f\"No checkpoints in {CKPT_DIR}\")\n",
        "\n",
        "checkpoint = str(ckpts[-1])\n",
        "print(f\"Using checkpoint: {checkpoint}\")\n",
        "\n",
        "!python inference.py   --image \"{IMAGE_PATH}\"   --checkpoint \"{checkpoint}\"   --backbone resnet50   --hash-dim 128   --proj-dim 512   --ttc-views 8   --stability-threshold 0.9   --hamming-threshold 10\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}