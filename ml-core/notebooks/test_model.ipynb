{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdDGu6veZCj8"
      },
      "source": [
        "# DaZZLeD Hash Center Training Notebook (ResNet + Counterfactual VAE)\n",
        "\n",
        "**Goal:** Train the ResNet Hash Center model from `resnet.tex` with counterfactual VAE, CF‑SimCLR, DHD, PGD, and TTC checks.\n",
        "\n",
        "**Runtime:** Set Colab to GPU before running training cells.\n",
        "\n",
        "**Note:** If you do not have VAE weights yet, you must train them first (Step 3). If you want a quick run without VAE, set `--counterfactual-mode aug` in Step 4.\n"
      ],
      "id": "NdDGu6veZCj8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yteox-CZCj9"
      },
      "source": [
        "## 0. Mount Google Drive\n"
      ],
      "id": "5Yteox-CZCj9"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7e73b613",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e73b613",
        "outputId": "51b88a0c-8afd-44ae-a5f9-d36a3b705178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "OK: Project root: /content/drive/MyDrive/dazzled\n",
            "OK: Data root: /content/drive/MyDrive/dazzled/data\n",
            "OK: Output root: /content/drive/MyDrive/dazzled/outputs\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (required for data storage)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directories\n",
        "from pathlib import Path\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "DATA_ROOT = DRIVE_ROOT / \"data\"\n",
        "OUTPUT_ROOT = DRIVE_ROOT / \"outputs\"\n",
        "\n",
        "# Create all needed directories\n",
        "for d in [\n",
        "    DATA_ROOT / \"ffhq\",\n",
        "    DATA_ROOT / \"openimages\",\n",
        "    DATA_ROOT / \"text\",\n",
        "    OUTPUT_ROOT / \"checkpoints\",\n",
        "    OUTPUT_ROOT / \"models\",\n",
        "    DRIVE_ROOT / \"manifests\",\n",
        "]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"OK: Project root: {DRIVE_ROOT}\")\n",
        "print(f\"OK: Data root: {DATA_ROOT}\")\n",
        "print(f\"OK: Output root: {OUTPUT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2b9b11e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9b11e9",
        "outputId": "17b08408-0cd7-43f7-ff45-2f2650788e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KAGGLE_USERNAME: OK\n",
            "KAGGLE_KEY: OK\n",
            "HF_TOKEN: OK\n"
          ]
        }
      ],
      "source": [
        "# Credentials check (Colab secrets)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    required = [\"KAGGLE_USERNAME\", \"KAGGLE_KEY\", \"HF_TOKEN\"]\n",
        "    for key in required:\n",
        "        val = userdata.get(key)\n",
        "        print(f\"{key}: {'OK' if val else 'MISSING'}\")\n",
        "except Exception as e:\n",
        "    print(\"Credentials check skipped:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9075e56",
      "metadata": {
        "id": "b9075e56"
      },
      "source": [
        "## 1. Setup & Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b33d410c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b33d410c",
        "outputId": "4df4c352-0404-4699-a0b9-5be404ff105c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DaZZLeD'...\n",
            "remote: Enumerating objects: 455, done.\u001b[K\n",
            "remote: Counting objects: 100% (455/455), done.\u001b[K\n",
            "remote: Compressing objects: 100% (275/275), done.\u001b[K\n",
            "remote: Total 455 (delta 201), reused 370 (delta 119), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (455/455), 272.17 KiB | 9.72 MiB/s, done.\n",
            "Resolving deltas: 100% (201/201), done.\n",
            "/content/DaZZLeD/ml-core\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists('DaZZLeD'):\n",
        "    !git clone https://github.com/D13ya/DaZZLeD.git\n",
        "    %cd DaZZLeD/ml-core\n",
        "else:\n",
        "    %cd DaZZLeD/ml-core\n",
        "\n",
        "!pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca3f2053",
      "metadata": {
        "id": "ca3f2053"
      },
      "source": [
        "## 2.1 Restore Dataset (Drive Zip)\n",
        "\n",
        "If you keep a dataset zip on Drive, extract it once to local disk (`/content/data`) for faster I/O.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "82a68b4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82a68b4a",
        "outputId": "7ba03522-1c87-4db6-de45-669b29c255dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found cached dataset on Drive: /content/drive/MyDrive/dazzled/data-cache/training-images.zip\n",
            "All datasets restored from cache successfully.\n",
            "  OK ffhq: 52,001 images\n",
            "  OK openimages: 2,500 images\n",
            "  OK mobileviews: 2,000 images\n",
            "Skipping downloads - data is ready.\n",
            "\n",
            "=================================================================\n",
            "FINAL DATASET VALIDATION\n",
            "=================================================================\n",
            "OK ffhq: 52,001 / 40,000 images\n",
            "OK openimages: 2,500 / 2,500 images\n",
            "OK mobileviews: 2,000 / 2,000 images\n",
            "Total: 56,501 images\n",
            "All datasets ready for training.\n"
          ]
        }
      ],
      "source": [
        "# DOWNLOAD & PREPARE DATASETS\n",
        "# FFHQ (Kaggle), OpenImages (FiftyOne), MobileViews (HF)\n",
        "# Restores from Drive cache if available; otherwise downloads and builds cache.\n",
        "\n",
        "import importlib\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "DATA_ROOT = Path(\"/content/data\")\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "DRIVE_ARCHIVE = DRIVE_ROOT / \"data-cache/training-images.zip\"\n",
        "\n",
        "# CHECK: Drive mounted\n",
        "if not Path(\"/content/drive/MyDrive\").exists():\n",
        "    raise RuntimeError(\n",
        "        \"Google Drive is NOT mounted. Run the mount cell first, then re-run this cell.\"\n",
        "    )\n",
        "\n",
        "EXPECTED_COUNTS = {\n",
        "    \"ffhq\": 40000,\n",
        "    \"openimages\": 2500,\n",
        "    \"mobileviews\": 2000,\n",
        "}\n",
        "\n",
        "def validate_dataset(data_root: Path, expected: dict):\n",
        "    results = {}\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "    for name, exp_count in expected.items():\n",
        "        path = data_root / name\n",
        "        if path.exists():\n",
        "            actual = len([p for p in path.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts])\n",
        "        else:\n",
        "            actual = 0\n",
        "        results[name] = {\"count\": actual, \"expected\": exp_count, \"valid\": actual >= exp_count * 0.95}\n",
        "    return all(r[\"valid\"] for r in results.values()), results\n",
        "\n",
        "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "need_download = {\"ffhq\": False, \"openimages\": False, \"mobileviews\": False}\n",
        "skip_downloads = False\n",
        "\n",
        "# Option 1: Restore from Drive cache\n",
        "if DRIVE_ARCHIVE.exists():\n",
        "    print(\"Found cached dataset on Drive:\", DRIVE_ARCHIVE)\n",
        "    shutil.unpack_archive(DRIVE_ARCHIVE, DATA_ROOT)\n",
        "    all_valid, validation = validate_dataset(DATA_ROOT, EXPECTED_COUNTS)\n",
        "    if all_valid:\n",
        "        print(\"All datasets restored from cache successfully.\")\n",
        "        for name, info in validation.items():\n",
        "            print(f\"  OK {name}: {info['count']:,} images\")\n",
        "        print(\"Skipping downloads - data is ready.\")\n",
        "        skip_downloads = True\n",
        "    else:\n",
        "        print(\"Cache incomplete; will download missing data:\")\n",
        "        for name, info in validation.items():\n",
        "            if not info[\"valid\"]:\n",
        "                need_download[name] = True\n",
        "                print(f\"  MISSING {name}: {info['count']:,}/{info['expected']:,}\")\n",
        "            else:\n",
        "                print(f\"  OK {name}: {info['count']:,} images\")\n",
        "else:\n",
        "    print(\"No cache found on Drive; downloading datasets.\")\n",
        "    need_download = {\"ffhq\": True, \"openimages\": True, \"mobileviews\": True}\n",
        "\n",
        "# Option 2: Download fresh data\n",
        "if not skip_downloads and any(need_download.values()):\n",
        "    print(\"\")\n",
        "    print(\"=\" * 65)\n",
        "    print(\"DOWNLOADING DATASETS\")\n",
        "    print(\"=\" * 65)\n",
        "\n",
        "    import torchvision.transforms as transforms\n",
        "    from PIL import Image\n",
        "    import io\n",
        "\n",
        "    # 1) FFHQ via Kaggle\n",
        "    if need_download[\"ffhq\"]:\n",
        "        ffhq_dir = DATA_ROOT / \"ffhq\"\n",
        "        ffhq_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"[1/3] FFHQ via Kaggle\")\n",
        "        print(\"Target: 40k face images\")\n",
        "\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            import os\n",
        "            os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "            os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")\n",
        "            print(\"Kaggle credentials loaded from Colab secrets\")\n",
        "        except Exception as e:\n",
        "            print(\"Could not load Kaggle secrets:\", e)\n",
        "            print(\"Add KAGGLE_USERNAME and KAGGLE_KEY to Colab secrets\")\n",
        "\n",
        "        subprocess.run([\n",
        "            \"kaggle\", \"datasets\", \"download\", \"-d\", \"arnaud58/flickrfaceshq-dataset-ffhq\",\n",
        "            \"-p\", str(ffhq_dir), \"--unzip\"\n",
        "        ], check=True)\n",
        "\n",
        "        # Flatten directory structure\n",
        "        for nested in ffhq_dir.rglob(\"*\"):\n",
        "            if nested.is_file() and nested.suffix.lower() in {\".jpg\", \".png\"}:\n",
        "                target = ffhq_dir / nested.name\n",
        "                if not target.exists():\n",
        "                    shutil.move(str(nested), str(target))\n",
        "\n",
        "        for d in ffhq_dir.iterdir():\n",
        "            if d.is_dir():\n",
        "                shutil.rmtree(d)\n",
        "\n",
        "        count = len(list(ffhq_dir.glob(\"*.jpg\"))) + len(list(ffhq_dir.glob(\"*.png\")))\n",
        "        print(f\"FFHQ: {count:,} images\")\n",
        "\n",
        "    # 2) OpenImages via FiftyOne\n",
        "    if need_download[\"openimages\"]:\n",
        "        oi_dir = DATA_ROOT / \"openimages\"\n",
        "        oi_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"[2/3] OpenImages via FiftyOne\")\n",
        "        print(\"Target: 2.5k diverse images\")\n",
        "\n",
        "        def ensure_fiftyone():\n",
        "            # 1. Forcefully clear any existing broken fiftyone modules from cache\n",
        "            to_remove = [m for m in sys.modules if m.startswith(\"fiftyone\")]\n",
        "            for m in to_remove:\n",
        "                del sys.modules[m]\n",
        "\n",
        "            # 2. Try importing fresh\n",
        "            try:\n",
        "                import fiftyone as fo\n",
        "                import fiftyone.zoo as foz\n",
        "                # Verify critical attribute exists\n",
        "                if not hasattr(fo, \"config\"):\n",
        "                    raise ImportError(\"fiftyone.config is missing\")\n",
        "                return fo, foz\n",
        "            except (ImportError, AttributeError):\n",
        "                return None, None\n",
        "\n",
        "        fo, foz = ensure_fiftyone()\n",
        "\n",
        "        if fo is None:\n",
        "            print(\"FiftyOne missing or broken. Installing...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"fiftyone\"])\n",
        "            # Re-run the clean import after install\n",
        "            fo, foz = ensure_fiftyone()\n",
        "\n",
        "        if fo is None:\n",
        "             raise RuntimeError(\"Failed to install/import fiftyone with valid config.\")\n",
        "\n",
        "        dataset = foz.load_zoo_dataset(\n",
        "            \"open-images-v7\",\n",
        "            split=\"validation\",\n",
        "            max_samples=2500,\n",
        "            shuffle=True,\n",
        "            seed=42,\n",
        "        )\n",
        "\n",
        "        for sample in dataset:\n",
        "            src = Path(sample.filepath)\n",
        "            dst = oi_dir / src.name\n",
        "            if src.exists() and not dst.exists():\n",
        "                shutil.copy2(src, dst)\n",
        "\n",
        "        count = len(list(oi_dir.glob(\"*\")))\n",
        "        print(f\"OpenImages: {count:,} images\")\n",
        "\n",
        "        fo.delete_dataset(dataset.name)\n",
        "\n",
        "    # Optional: Hugging Face token (for gated datasets)\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        from huggingface_hub import login\n",
        "        hf_token = userdata.get(\"HF_TOKEN\")\n",
        "        if hf_token:\n",
        "            login(hf_token)\n",
        "            print(\"HF token loaded\")\n",
        "        else:\n",
        "            print(\"HF_TOKEN not found in Colab secrets\")\n",
        "    except Exception as e:\n",
        "        print(\"HF login skipped:\", e)\n",
        "\n",
        "    # 3) MobileViews via HuggingFace\n",
        "    if need_download[\"mobileviews\"]:\n",
        "        mv_dir = DATA_ROOT / \"mobileviews\"\n",
        "        mv_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"[3/3] MobileViews via HuggingFace\")\n",
        "        print(\"Target: 2k mobile UI screenshots\")\n",
        "\n",
        "        try:\n",
        "            from datasets import load_dataset\n",
        "\n",
        "            ds = load_dataset(\n",
        "                \"mllmTeam/MobileViews\",\n",
        "                split=\"train\",\n",
        "                streaming=True,\n",
        "            )\n",
        "\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
        "            ])\n",
        "\n",
        "            count = 0\n",
        "            target = 2000\n",
        "            for sample in ds:\n",
        "                if count >= target:\n",
        "                    break\n",
        "                try:\n",
        "                    img = sample.get(\"image\")\n",
        "                    if img is not None:\n",
        "                        img = transform(img)\n",
        "                        img.save(mv_dir / f\"mv_{count:05d}.jpg\", \"JPEG\", quality=85)\n",
        "                        count += 1\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "            print(f\"MobileViews: {count:,} images\")\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"datasets not installed. Installing...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n",
        "            print(\"Re-run this cell after installation\")\n",
        "\n",
        "    # Save cache to Drive\n",
        "    print(\"\")\n",
        "    print(\"=\" * 65)\n",
        "    print(\"SAVING CACHE TO DRIVE\")\n",
        "    print(\"=\" * 65)\n",
        "\n",
        "    DRIVE_ARCHIVE.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(\"Creating archive:\", DRIVE_ARCHIVE)\n",
        "    shutil.make_archive(\n",
        "        str(DRIVE_ARCHIVE.with_suffix(\"\")),\n",
        "        \"zip\",\n",
        "        DATA_ROOT,\n",
        "    )\n",
        "\n",
        "    archive_size = DRIVE_ARCHIVE.stat().st_size / (1024 ** 3)\n",
        "    print(f\"Cache saved ({archive_size:.2f} GB)\")\n",
        "\n",
        "# Final validation\n",
        "print(\"\")\n",
        "print(\"=\" * 65)\n",
        "print(\"FINAL DATASET VALIDATION\")\n",
        "print(\"=\" * 65)\n",
        "\n",
        "all_valid, validation = validate_dataset(DATA_ROOT, EXPECTED_COUNTS)\n",
        "total_images = sum(info[\"count\"] for info in validation.values())\n",
        "\n",
        "for name, info in validation.items():\n",
        "    status = \"OK\" if info[\"valid\"] else \"BAD\"\n",
        "    print(f\"{status} {name}: {info['count']:,} / {info['expected']:,} images\")\n",
        "\n",
        "print(f\"Total: {total_images:,} images\")\n",
        "\n",
        "if all_valid:\n",
        "    print(\"All datasets ready for training.\")\n",
        "else:\n",
        "    print(\"Some datasets are incomplete. Re-run this cell to download more.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0d006700",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d006700",
        "outputId": "c412ad57-cbc8-467f-f8fa-5dce01a99c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating DATA_ROOT: /content/data\n",
            "Total images found: 56501\n",
            "Extension counts: {'.png': 52001, '.jpg': 4500}\n",
            "Sample check: all images readable and convertible to RGB.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "\n",
        "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "\n",
        "if \"DATA_ROOT\" not in globals():\n",
        "    DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "    LOCAL_DATA = Path(\"/content/data\")\n",
        "    DRIVE_DATA = DRIVE_ROOT / \"data\"\n",
        "    def has_images(root: Path) -> bool:\n",
        "        if not root.exists():\n",
        "            return False\n",
        "        return any(p.is_file() and p.suffix.lower() in exts for p in root.rglob(\"*\"))\n",
        "    DATA_ROOT = LOCAL_DATA if has_images(LOCAL_DATA) else DRIVE_DATA\n",
        "\n",
        "print(f\"Validating DATA_ROOT: {DATA_ROOT}\")\n",
        "\n",
        "paths = [p for p in DATA_ROOT.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts]\n",
        "print(f\"Total images found: {len(paths)}\")\n",
        "\n",
        "ext_counts = Counter(p.suffix.lower() for p in paths)\n",
        "print(\"Extension counts:\", dict(ext_counts))\n",
        "\n",
        "sample = paths[:200]\n",
        "bad = []\n",
        "for p in sample:\n",
        "    try:\n",
        "        with Image.open(p) as img:\n",
        "            img.convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        bad.append((p, str(e)))\n",
        "\n",
        "if bad:\n",
        "    print(f\"Corrupt/unreadable samples: {len(bad)} (showing up to 5)\")\n",
        "    for p, err in bad[:5]:\n",
        "        print(f\"  - {p}: {err}\")\n",
        "else:\n",
        "    print(\"Sample check: all images readable and convertible to RGB.\")\n",
        "\n",
        "if len(paths) == 0:\n",
        "    raise ValueError(\"No images found for training. Check extraction paths or zip contents.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "498c0056",
      "metadata": {
        "id": "498c0056"
      },
      "source": [
        "## 2.2 Build Manifest (Optional)\n",
        "\n",
        "If you already have a manifest at `/content/drive/MyDrive/dazzled/manifests/train.txt`, you can skip this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a4155434",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4155434",
        "outputId": "5c21407d-ba5c-48a7-d199-b206bd42d32f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using DATA_ROOT: /content/data\n",
            "Wrote 56501 lines to /content/drive/MyDrive/dazzled/manifests/train.txt (per-image labels)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "LOCAL_DATA = Path(\"/content/data\")\n",
        "DRIVE_DATA = DRIVE_ROOT / \"data\"\n",
        "MANIFEST = DRIVE_ROOT / \"manifests/train.txt\"\n",
        "MANIFEST.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "LABEL_REGEX = re.compile(r\"^((?:ffhq|openimages|openimg|mobileviews?)_\\d+|\\d+)\")\n",
        "\n",
        "def has_images(root: Path) -> bool:\n",
        "    if not root.exists():\n",
        "        return False\n",
        "    return any(p.is_file() and p.suffix.lower() in exts for p in root.rglob(\"*\"))\n",
        "\n",
        "DATA_ROOT = LOCAL_DATA if has_images(LOCAL_DATA) else DRIVE_DATA\n",
        "print(f\"Using DATA_ROOT: {DATA_ROOT}\")\n",
        "\n",
        "lines = []\n",
        "for p in DATA_ROOT.rglob(\"*\"):\n",
        "    if not p.is_file() or p.suffix.lower() not in exts:\n",
        "        continue\n",
        "    match = LABEL_REGEX.search(p.name)\n",
        "    label = match.group(1) if match else p.stem\n",
        "    lines.append(f\"{p} {label}\")\n",
        "\n",
        "MANIFEST.write_text(\"\\n\".join(lines))\n",
        "print(f\"Wrote {len(lines)} lines to {MANIFEST} (per-image labels)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f6eb8d6",
      "metadata": {
        "id": "7f6eb8d6"
      },
      "source": [
        "## 2.5. Sanity Checks (Labels + Domains)\n",
        "\n",
        "Run this once after the manifest is created to verify labels/domains before any training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6829455a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6829455a",
        "outputId": "4fcce1b6-d6c6-4f3f-b409-64d0dbcc9e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label stats: 55569 unique, 0/56501 unlabeled (0.0%).\n",
            "Top labels: 5:67, 4:62, 2:61, 3:61, 7:57\n",
            "Domain stats: 3 unique, 0/56501 unlabeled (0.0%).\n",
            "Top domains: ffhq:52001, openimages:2500, mobileviews:2000\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "MANIFEST = Path(\"/content/drive/MyDrive/dazzled/manifests/train.txt\")\n",
        "LABEL_REGEX = re.compile(r\"^((?:ffhq|openimages|openimg|mobileview)_\\d+|\\d+)\")\n",
        "DOMAIN_REGEX = re.compile(r\"(?:^|/)(ffhq|openimages|openimg|mobileviews?)(?:/|_)\")\n",
        "\n",
        "if not MANIFEST.exists():\n",
        "    raise FileNotFoundError(f\"Manifest not found: {MANIFEST}\")\n",
        "\n",
        "base = MANIFEST.resolve().parent\n",
        "lines = [line.strip() for line in MANIFEST.read_text().splitlines() if line.strip() and not line.strip().startswith('#')]\n",
        "total = len(lines)\n",
        "\n",
        "labels = []\n",
        "domains = []\n",
        "missing = []\n",
        "\n",
        "for line in lines:\n",
        "    parts = line.split()\n",
        "    path = Path(parts[0])\n",
        "    if not path.is_absolute():\n",
        "        path = (base / path).resolve()\n",
        "\n",
        "    label = parts[1] if len(parts) > 1 else None\n",
        "    if label is None:\n",
        "        match = LABEL_REGEX.search(path.name)\n",
        "        if match:\n",
        "            label = match.group(1)\n",
        "\n",
        "    domain = None\n",
        "    match = DOMAIN_REGEX.search(str(path))\n",
        "    if match:\n",
        "        domain = match.group(1)\n",
        "\n",
        "    labels.append(label)\n",
        "    domains.append(domain)\n",
        "    if not path.exists():\n",
        "        missing.append(str(path))\n",
        "\n",
        "label_known = [str(l) for l in labels if l is not None]\n",
        "domain_known = [str(d) for d in domains if d is not None]\n",
        "\n",
        "label_unique = len(set(label_known))\n",
        "label_unlabeled = total - len(label_known)\n",
        "label_pct = (label_unlabeled / total * 100.0) if total else 0.0\n",
        "\n",
        "domain_unique = len(set(domain_known))\n",
        "domain_unlabeled = total - len(domain_known)\n",
        "domain_pct = (domain_unlabeled / total * 100.0) if total else 0.0\n",
        "\n",
        "print(f\"Label stats: {label_unique} unique, {label_unlabeled}/{total} unlabeled ({label_pct:.1f}%).\")\n",
        "if label_known:\n",
        "    top = Counter(label_known).most_common(5)\n",
        "    top_str = \", \".join(f\"{k}:{v}\" for k, v in top)\n",
        "    print(f\"Top labels: {top_str}\")\n",
        "\n",
        "print(f\"Domain stats: {domain_unique} unique, {domain_unlabeled}/{total} unlabeled ({domain_pct:.1f}%).\")\n",
        "if domain_known:\n",
        "    top = Counter(domain_known).most_common(5)\n",
        "    top_str = \", \".join(f\"{k}:{v}\" for k, v in top)\n",
        "    print(f\"Top domains: {top_str}\")\n",
        "\n",
        "if missing:\n",
        "    print(f\"Missing files: {len(missing)} (showing up to 5)\")\n",
        "    for p in missing[:5]:\n",
        "        print(f\"  - {p}\")\n",
        "\n",
        "if label_unique < 2:\n",
        "    raise ValueError(\"CRITICAL: fewer than 2 unique labels found. Check regex/manifest.\")\n",
        "if domain_unique < 2:\n",
        "    print(\"WARNING: fewer than 2 unique domains found; VAE training will fail.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb30d68f",
      "metadata": {
        "id": "eb30d68f"
      },
      "source": [
        "## 3. Train Counterfactual VAE (Save Weights)\n",
        "\n",
        "This produces the `--counterfactual-weights` file used by HashNet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f1d11bf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1d11bf0",
        "outputId": "9a4b2d9f-7ff5-4eba-895a-e6f119125809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Domain stats: 3 unique, 0/56501 unlabeled (0.0%).\n",
            "Top domains: ffhq:52001, openimages:2500, mobileviews:2000\n",
            "Dataset: 56501 images, 588 batches\n",
            "\n",
            "======================================================================\n",
            "Counterfactual VAE Training\n",
            "======================================================================\n",
            "Domains: 3\n",
            "Batch: 96, Epochs: 10\n",
            "LR: 0.0001, WD: 0.01\n",
            "======================================================================\n",
            "\n",
            "E1 B50 loss=575423.1875 recon=575009.6250 kld=413.5504\n",
            "E1 B100 loss=555152.5625 recon=554856.3750 kld=296.1842\n",
            "E1 B150 loss=470267.3438 recon=469912.6250 kld=354.6986\n",
            "E1 B200 loss=378435.1875 recon=378015.5417 kld=419.6417\n",
            "E1 B250 loss=408987.1875 recon=408496.3750 kld=490.7999\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DaZZLeD/ml-core/training/train_counterfactual_vae.py\", line 383, in <module>\n",
            "    main()\n",
            "  File \"/content/DaZZLeD/ml-core/training/train_counterfactual_vae.py\", line 379, in main\n",
            "    train(args)\n",
            "  File \"/content/DaZZLeD/ml-core/training/train_counterfactual_vae.py\", line 291, in train\n",
            "    for batch_idx, batch in enumerate(loader, start=1):\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1479, in _next_data\n",
            "    return self._process_data(data, worker_id)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_utils.py\", line 769, in reraise\n",
            "    raise exception\n",
            "OSError: Caught OSError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/ImageFile.py\", line 370, in load\n",
            "    s = read(read_bytes)\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/PngImagePlugin.py\", line 994, in load_read\n",
            "    cid, pos, length = self.png.read()\n",
            "                       ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/PngImagePlugin.py\", line 176, in read\n",
            "    length = i32(s)\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/_binary.py\", line 95, in i32be\n",
            "    return unpack_from(\">I\", c, o)[0]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "struct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "            ~~~~~~~~~~~~^^^^^\n",
            "  File \"/content/DaZZLeD/ml-core/training/train_counterfactual_vae.py\", line 178, in __getitem__\n",
            "    img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 986, in convert\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/ImageFile.py\", line 377, in load\n",
            "    raise OSError(msg) from e\n",
            "OSError: image file is truncated\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DaZZLeD/ml-core\")\n",
        "\n",
        "!PYTHONPATH=/content/DaZZLeD/ml-core python training/train_counterfactual_vae.py \\\n",
        "  --data-list /content/drive/MyDrive/dazzled/manifests/train.txt \\\n",
        "  --epochs 10 \\\n",
        "  --batch-size 96 \\\n",
        "  --checkpoint-dir /content/drive/MyDrive/dazzled/outputs/cf_vae \\\n",
        "  --domain-mode regex \\\n",
        "  --domain-regex \"(?:^|/)(ffhq|openimages|openimg|mobileviews?)(?:/|_)\" \\\n",
        "  --workers 4 \\\n",
        "  --prefetch-factor 2 \\\n",
        "  --pin-memory \\\n",
        "  --amp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f1a592",
      "metadata": {
        "id": "92f1a592"
      },
      "source": [
        "## 4. Train HashNet (ResNet + Hash Centers + CF/DHD/PGD)\n",
        "\n",
        "This uses the VAE weights from Step 3 and writes checkpoints to Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "021fc9a7",
      "metadata": {
        "id": "021fc9a7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DaZZLeD/ml-core\")\n",
        "\n",
        "!PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True \\\n",
        "PYTHONPATH=/content/DaZZLeD/ml-core \\\n",
        "python training/train_hashnet.py \\\n",
        "  --data-list /content/drive/MyDrive/dazzled/manifests/train.txt \\\n",
        "  --epochs 10 \\\n",
        "  --batch-size 64 \\\n",
        "  --center-mode random \\\n",
        "  --extra-negatives 1024 \\\n",
        "  --center-neg-k 0 \\\n",
        "  --counterfactual-mode vae \\\n",
        "  --counterfactual-weights /content/drive/MyDrive/dazzled/outputs/cf_vae/cf_vae_final.safetensors \\\n",
        "  --checkpoint-dir /content/drive/MyDrive/dazzled/outputs/hashnet \\\n",
        "  --domain-mode regex \\\n",
        "  --domain-regex '(?:^|/)(ffhq|openimages|openimg|mobileviews?)(?:/|_)' \\\n",
        "  --workers 2 \\\n",
        "  --prefetch-factor 1 \\\n",
        "  --pin-memory \\\n",
        "  --amp \\\n",
        "  --channels-last \\\n",
        "  --allow-tf32 \\\n",
        "  --cudnn-benchmark \\\n",
        "  --lr 3e-4 \\\n",
        "  --warmup-steps 500 \\\n",
        "  --center-weight 10 \\\n",
        "  --distinct-weight 0.5 \\\n",
        "  --quant-weight 0.1 \\\n",
        "  --cf-weight 0.1 \\\n",
        "  --dhd-weight 0.1 \\\n",
        "  --adv-weight 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9-CmxrdZCkA"
      },
      "source": [
        "## 5. List Checkpoints\n"
      ],
      "id": "P9-CmxrdZCkA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhB6l1zOZCkA"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "CKPT_DIR = Path(\"/content/drive/MyDrive/dazzled/outputs/hashnet\")\n",
        "ckpts = sorted(CKPT_DIR.glob(\"*.safetensors\"))\n",
        "print(f\"Found {len(ckpts)} checkpoints\")\n",
        "for ckpt in ckpts:\n",
        "    print(ckpt.name)\n"
      ],
      "id": "JhB6l1zOZCkA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQU-_B1PZCkA"
      },
      "source": [
        "## 6. TTC Inference (Production-Style)\n",
        "\n",
        "Run the standalone TTC inference script on a sample image.\n"
      ],
      "id": "NQU-_B1PZCkA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FFi8vF8ZCkA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DaZZLeD/ml-core\")\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "CKPT_DIR = Path(\"/content/drive/MyDrive/dazzled/outputs/hashnet\")\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/dazzled/data/ffhq/224/00000.jpg\"  # TODO: set a real path\n",
        "\n",
        "ckpts = sorted(CKPT_DIR.glob(\"*.safetensors\"))\n",
        "if not ckpts:\n",
        "    raise FileNotFoundError(f\"No checkpoints in {CKPT_DIR}\")\n",
        "\n",
        "checkpoint = str(ckpts[-1])\n",
        "print(f\"Using checkpoint: {checkpoint}\")\n",
        "\n",
        "!python inference.py   --image \"{IMAGE_PATH}\"   --checkpoint \"{checkpoint}\"   --backbone resnet50   --hash-dim 128   --proj-dim 512   --ttc-views 8   --stability-threshold 0.9   --hamming-threshold 10\n"
      ],
      "id": "6FFi8vF8ZCkA"
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}