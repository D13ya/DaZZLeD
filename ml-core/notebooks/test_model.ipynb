{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DaZZLeD Hash Center Training Notebook (ResNet + Counterfactual VAE)\n",
        "\n",
        "**Goal:** Train the ResNet Hash Center model from `resnet.tex` with counterfactual VAE, CF\u2011SimCLR, DHD, PGD, and TTC checks.\n",
        "\n",
        "**Runtime:** Set Colab to GPU before running training cells.\n",
        "\n",
        "**Note:** If you do not have VAE weights yet, you must train them first (Step 3). If you want a quick run without VAE, set `--counterfactual-mode aug` in Step 4.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "DATA_ROOT = DRIVE_ROOT / \"data\"\n",
        "OUTPUT_ROOT = DRIVE_ROOT / \"outputs\"\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists('DaZZLeD'):\n",
        "    !git clone https://github.com/D13ya/DaZZLeD.git\n",
        "    %cd DaZZLeD/ml-core\n",
        "else:\n",
        "    %cd DaZZLeD/ml-core\n",
        "\n",
        "!pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Restore Dataset (Drive Zip)\n",
        "\n",
        "If you keep a dataset zip on Drive, extract it once to local disk (`/content/data`) for faster I/O.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import zipfile\n",
        "import shutil\n",
        "import urllib.request\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "LOCAL_DATA = Path(\"/content/data\")\n",
        "LOCAL_DATA.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RESET_LOCAL = True  # set False to reuse existing /content/data\n",
        "DATASET_URL = \"\"    # optional: direct http(s) link to a zip file\n",
        "BUILD_CACHE_ZIP = True  # write training-images.zip after extraction if missing\n",
        "\n",
        "CACHE_ZIP = DRIVE_ROOT / \"data-cache/training-images.zip\"\n",
        "ALT_ZIP = DRIVE_ROOT / \"dazzled_dataset_v4.zip\"\n",
        "\n",
        "if RESET_LOCAL and LOCAL_DATA.exists():\n",
        "    shutil.rmtree(LOCAL_DATA)\n",
        "    LOCAL_DATA.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "\n",
        "def count_images(root: Path) -> int:\n",
        "    return sum(\n",
        "        1 for p in root.rglob(\"*\")\n",
        "        if p.is_file() and p.suffix.lower() in exts\n",
        "    )\n",
        "\n",
        "def extract_zip(zip_path: Path, dest: Path) -> int:\n",
        "    print(f\"Extracting {zip_path} -> {dest}\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "        zf.extractall(dest)\n",
        "    extracted = count_images(dest)\n",
        "    print(f\"Extracted {extracted} images to {dest}\")\n",
        "    return extracted\n",
        "\n",
        "def download_zip(url: str, dest: Path) -> None:\n",
        "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Downloading {url} -> {dest}\")\n",
        "    urllib.request.urlretrieve(url, dest)\n",
        "\n",
        "existing = count_images(LOCAL_DATA)\n",
        "if existing > 0 and not RESET_LOCAL:\n",
        "    print(f\"Local data already present under {LOCAL_DATA} ({existing} images); skipping extract.\")\n",
        "else:\n",
        "    extracted = 0\n",
        "    source = None\n",
        "\n",
        "    if CACHE_ZIP.exists():\n",
        "        source = CACHE_ZIP\n",
        "    elif ALT_ZIP.exists():\n",
        "        source = ALT_ZIP\n",
        "    elif DATASET_URL:\n",
        "        download_zip(DATASET_URL, CACHE_ZIP)\n",
        "        source = CACHE_ZIP\n",
        "\n",
        "    if source is not None:\n",
        "        extracted = extract_zip(source, LOCAL_DATA)\n",
        "\n",
        "    if extracted == 0:\n",
        "        nested = [p for p in LOCAL_DATA.rglob(\"*.zip\") if p.is_file()]\n",
        "        for nested_zip in nested:\n",
        "            if source is not None and nested_zip.resolve() == source.resolve():\n",
        "                continue\n",
        "            extracted = extract_zip(nested_zip, LOCAL_DATA)\n",
        "            if extracted > 0:\n",
        "                break\n",
        "\n",
        "    if extracted == 0:\n",
        "        print(\"No images found after extraction. Check the zip contents or path.\")\n",
        "\n",
        "    if BUILD_CACHE_ZIP and extracted > 0 and not CACHE_ZIP.exists():\n",
        "        print(f\"Building cache zip at {CACHE_ZIP}\")\n",
        "        CACHE_ZIP.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with zipfile.ZipFile(CACHE_ZIP, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "            for p in LOCAL_DATA.rglob(\"*\"):\n",
        "                if p.is_file():\n",
        "                    zf.write(p, p.relative_to(LOCAL_DATA))\n",
        "        print(f\"Wrote cache zip: {CACHE_ZIP}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "\n",
        "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "\n",
        "if \"DATA_ROOT\" not in globals():\n",
        "    DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "    LOCAL_DATA = Path(\"/content/data\")\n",
        "    DRIVE_DATA = DRIVE_ROOT / \"data\"\n",
        "    def has_images(root: Path) -> bool:\n",
        "        if not root.exists():\n",
        "            return False\n",
        "        return any(p.is_file() and p.suffix.lower() in exts for p in root.rglob(\"*\"))\n",
        "    DATA_ROOT = LOCAL_DATA if has_images(LOCAL_DATA) else DRIVE_DATA\n",
        "\n",
        "print(f\"Validating DATA_ROOT: {DATA_ROOT}\")\n",
        "\n",
        "paths = [p for p in DATA_ROOT.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts]\n",
        "print(f\"Total images found: {len(paths)}\")\n",
        "\n",
        "ext_counts = Counter(p.suffix.lower() for p in paths)\n",
        "print(\"Extension counts:\", dict(ext_counts))\n",
        "\n",
        "sample = paths[:200]\n",
        "bad = []\n",
        "for p in sample:\n",
        "    try:\n",
        "        with Image.open(p) as img:\n",
        "            img.convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        bad.append((p, str(e)))\n",
        "\n",
        "if bad:\n",
        "    print(f\"Corrupt/unreadable samples: {len(bad)} (showing up to 5)\")\n",
        "    for p, err in bad[:5]:\n",
        "        print(f\"  - {p}: {err}\")\n",
        "else:\n",
        "    print(\"Sample check: all images readable and convertible to RGB.\")\n",
        "\n",
        "if len(paths) == 0:\n",
        "    raise ValueError(\"No images found for training. Check extraction paths or zip contents.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Build Manifest (Optional)\n\nIf you already have a manifest at `/content/drive/MyDrive/dazzled/manifests/train.txt`, you can skip this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/dazzled\")\n",
        "LOCAL_DATA = Path(\"/content/data\")\n",
        "DRIVE_DATA = DRIVE_ROOT / \"data\"\n",
        "MANIFEST = DRIVE_ROOT / \"manifests/train.txt\"\n",
        "MANIFEST.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "LABEL_REGEX = re.compile(r\"^((?:ffhq|openimages|openimg|mobileviews?)_\\d+|\\d+)\")\n",
        "\n",
        "def has_images(root: Path) -> bool:\n",
        "    if not root.exists():\n",
        "        return False\n",
        "    return any(p.is_file() and p.suffix.lower() in exts for p in root.rglob(\"*\"))\n",
        "\n",
        "DATA_ROOT = LOCAL_DATA if has_images(LOCAL_DATA) else DRIVE_DATA\n",
        "print(f\"Using DATA_ROOT: {DATA_ROOT}\")\n",
        "\n",
        "lines = []\n",
        "for p in DATA_ROOT.rglob(\"*\"):\n",
        "    if not p.is_file() or p.suffix.lower() not in exts:\n",
        "        continue\n",
        "    match = LABEL_REGEX.search(p.name)\n",
        "    label = match.group(1) if match else p.stem\n",
        "    lines.append(f\"{p} {label}\")\n",
        "\n",
        "MANIFEST.write_text(\"\\n\".join(lines))\n",
        "print(f\"Wrote {len(lines)} lines to {MANIFEST} (per-image labels)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.5. Sanity Checks (Labels + Domains)\n",
        "\n",
        "Run this once after the manifest is created to verify labels/domains before any training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "MANIFEST = Path(\"/content/drive/MyDrive/dazzled/manifests/train.txt\")\n",
        "LABEL_REGEX = re.compile(r\"^((?:ffhq|openimages|openimg|mobileview)_\\d+|\\d+)\")\n",
        "DOMAIN_REGEX = re.compile(r\"(?:^|/)(ffhq|openimages|openimg|mobileviews?)(?:/|_)\")\n",
        "\n",
        "if not MANIFEST.exists():\n",
        "    raise FileNotFoundError(f\"Manifest not found: {MANIFEST}\")\n",
        "\n",
        "base = MANIFEST.resolve().parent\n",
        "lines = [line.strip() for line in MANIFEST.read_text().splitlines() if line.strip() and not line.strip().startswith('#')]\n",
        "total = len(lines)\n",
        "\n",
        "labels = []\n",
        "domains = []\n",
        "missing = []\n",
        "\n",
        "for line in lines:\n",
        "    parts = line.split()\n",
        "    path = Path(parts[0])\n",
        "    if not path.is_absolute():\n",
        "        path = (base / path).resolve()\n",
        "\n",
        "    label = parts[1] if len(parts) > 1 else None\n",
        "    if label is None:\n",
        "        match = LABEL_REGEX.search(path.name)\n",
        "        if match:\n",
        "            label = match.group(1)\n",
        "\n",
        "    domain = None\n",
        "    match = DOMAIN_REGEX.search(str(path))\n",
        "    if match:\n",
        "        domain = match.group(1)\n",
        "\n",
        "    labels.append(label)\n",
        "    domains.append(domain)\n",
        "    if not path.exists():\n",
        "        missing.append(str(path))\n",
        "\n",
        "label_known = [str(l) for l in labels if l is not None]\n",
        "domain_known = [str(d) for d in domains if d is not None]\n",
        "\n",
        "label_unique = len(set(label_known))\n",
        "label_unlabeled = total - len(label_known)\n",
        "label_pct = (label_unlabeled / total * 100.0) if total else 0.0\n",
        "\n",
        "domain_unique = len(set(domain_known))\n",
        "domain_unlabeled = total - len(domain_known)\n",
        "domain_pct = (domain_unlabeled / total * 100.0) if total else 0.0\n",
        "\n",
        "print(f\"Label stats: {label_unique} unique, {label_unlabeled}/{total} unlabeled ({label_pct:.1f}%).\")\n",
        "if label_known:\n",
        "    top = Counter(label_known).most_common(5)\n",
        "    top_str = \", \".join(f\"{k}:{v}\" for k, v in top)\n",
        "    print(f\"Top labels: {top_str}\")\n",
        "\n",
        "print(f\"Domain stats: {domain_unique} unique, {domain_unlabeled}/{total} unlabeled ({domain_pct:.1f}%).\")\n",
        "if domain_known:\n",
        "    top = Counter(domain_known).most_common(5)\n",
        "    top_str = \", \".join(f\"{k}:{v}\" for k, v in top)\n",
        "    print(f\"Top domains: {top_str}\")\n",
        "\n",
        "if missing:\n",
        "    print(f\"Missing files: {len(missing)} (showing up to 5)\")\n",
        "    for p in missing[:5]:\n",
        "        print(f\"  - {p}\")\n",
        "\n",
        "if label_unique < 2:\n",
        "    raise ValueError(\"CRITICAL: fewer than 2 unique labels found. Check regex/manifest.\")\n",
        "if domain_unique < 2:\n",
        "    print(\"WARNING: fewer than 2 unique domains found; VAE training will fail.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Counterfactual VAE (Save Weights)\n",
        "\n",
        "This produces the `--counterfactual-weights` file used by HashNet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DaZZLeD/ml-core\")\n",
        "\n",
        "!PYTHONPATH=/content/DaZZLeD/ml-core python training/train_counterfactual_vae.py \\\n",
        "  --data-list /content/drive/MyDrive/dazzled/manifests/train.txt \\\n",
        "  --epochs 10 \\\n",
        "  --batch-size 96 \\\n",
        "  --checkpoint-dir /content/drive/MyDrive/dazzled/outputs/cf_vae \\\n",
        "  --domain-mode regex \\\n",
        "  --domain-regex \"(?:^|/)(ffhq|openimages|openimg|mobileviews?)(?:/|_)\" \\\n",
        "  --workers 4 \\\n",
        "  --prefetch-factor 2 \\\n",
        "  --pin-memory \\\n",
        "  --amp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train HashNet (ResNet + Hash Centers + CF/DHD/PGD)\n",
        "\n",
        "This uses the VAE weights from Step 3 and writes checkpoints to Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DaZZLeD/ml-core\")\n",
        "\n",
        "!PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True \\\n",
        "PYTHONPATH=/content/DaZZLeD/ml-core \\\n",
        "python training/train_hashnet.py \\\n",
        "  --data-list /content/drive/MyDrive/dazzled/manifests/train.txt \\\n",
        "  --epochs 10 \\\n",
        "  --batch-size 64 \\\n",
        "  --center-mode random \\\n",
        "  --extra-negatives 1024 \\\n",
        "  --center-neg-k 0 \\\n",
        "  --counterfactual-mode vae \\\n",
        "  --counterfactual-weights /content/drive/MyDrive/dazzled/outputs/cf_vae/cf_vae_final.safetensors \\\n",
        "  --checkpoint-dir /content/drive/MyDrive/dazzled/outputs/hashnet \\\n",
        "  --domain-mode regex \\\n",
        "  --domain-regex '(?:^|/)(ffhq|openimages|openimg|mobileviews?)(?:/|_)' \\\n",
        "  --workers 2 \\\n",
        "  --prefetch-factor 1 \\\n",
        "  --pin-memory \\\n",
        "  --amp \\\n",
        "  --channels-last \\\n",
        "  --allow-tf32 \\\n",
        "  --cudnn-benchmark \\\n",
        "  --lr 3e-4 \\\n",
        "  --warmup-steps 500 \\\n",
        "  --center-weight 10 \\\n",
        "  --distinct-weight 0.5 \\\n",
        "  --quant-weight 0.1 \\\n",
        "  --cf-weight 0.1 \\\n",
        "  --dhd-weight 0.1 \\\n",
        "  --adv-weight 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. List Checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "CKPT_DIR = Path(\"/content/drive/MyDrive/dazzled/outputs/hashnet\")\n",
        "ckpts = sorted(CKPT_DIR.glob(\"*.safetensors\"))\n",
        "print(f\"Found {len(ckpts)} checkpoints\")\n",
        "for ckpt in ckpts:\n",
        "    print(ckpt.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. TTC Inference (Production-Style)\n",
        "\n",
        "Run the standalone TTC inference script on a sample image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DaZZLeD/ml-core\")\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "CKPT_DIR = Path(\"/content/drive/MyDrive/dazzled/outputs/hashnet\")\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/dazzled/data/ffhq/224/00000.jpg\"  # TODO: set a real path\n",
        "\n",
        "ckpts = sorted(CKPT_DIR.glob(\"*.safetensors\"))\n",
        "if not ckpts:\n",
        "    raise FileNotFoundError(f\"No checkpoints in {CKPT_DIR}\")\n",
        "\n",
        "checkpoint = str(ckpts[-1])\n",
        "print(f\"Using checkpoint: {checkpoint}\")\n",
        "\n",
        "!python inference.py   --image \"{IMAGE_PATH}\"   --checkpoint \"{checkpoint}\"   --backbone resnet50   --hash-dim 128   --proj-dim 512   --ttc-views 8   --stability-threshold 0.9   --hamming-threshold 10\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}